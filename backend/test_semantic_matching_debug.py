#!/usr/bin/env python3
"""
æµ‹è¯•è¯­ä¹‰åŒ¹é…é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ä¸ºä»€ä¹ˆchair_on_ylineæ€»æ˜¯è¢«é”™è¯¯è¯†åˆ«
"""

import json
import re

def load_structure_data():
    """åŠ è½½ç»“æ„æ•°æ®"""
    try:
        with open('data/Sense_A_Finetuned.fixed.jsonl', 'r', encoding='utf-8') as f:
            content = f.read()
            data = json.loads(content)
            return data
    except Exception as e:
        print(f"âŒ åŠ è½½ç»“æ„æ•°æ®å¤±è´¥: {e}")
        return None

def analyze_node_index_terms(data):
    """åˆ†æèŠ‚ç‚¹çš„ç´¢å¼•è¯"""
    if not data or 'input' not in data or 'topology' not in data['input']:
        print("âŒ æ•°æ®ç»“æ„ä¸å®Œæ•´")
        return
    
    nodes = data['input']['topology']['nodes']
    print("ğŸ” åˆ†æèŠ‚ç‚¹ç´¢å¼•è¯å’Œè¯­ä¹‰åŒ¹é…")
    print("=" * 60)
    
    # æµ‹è¯•å›¾ç‰‡æè¿°
    test_captions = [
        "there is a table with a bunch of electronics on it",
        "there is a book shelf with books and a sign on it", 
        "there is a cat sitting on a chair in a room",
        "there are many different types of electronics on the table"
    ]
    
    for caption in test_captions:
        print(f"\nğŸ“¸ æµ‹è¯•å›¾ç‰‡æè¿°: {caption}")
        print("-" * 40)
        
        # åˆ†ææ¯ä¸ªèŠ‚ç‚¹çš„åŒ¹é…åº¦
        node_scores = []
        for node in nodes:
            node_id = node['id']
            index_terms = node.get('retrieval', {}).get('index_terms', [])
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0
            matched_terms = []
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            caption_lower = caption.lower()
            for term in index_terms:
                term_lower = term.lower()
                if term_lower in caption_lower:
                    score += 1
                    matched_terms.append(term)
                # æ£€æŸ¥éƒ¨åˆ†åŒ¹é…
                elif any(word in caption_lower for word in term_lower.split()):
                    score += 0.5
                    matched_terms.append(f"{term}(partial)")
            
            if score > 0:
                node_scores.append({
                    'node_id': node_id,
                    'score': score,
                    'matched_terms': matched_terms,
                    'index_terms': index_terms[:5]  # åªæ˜¾ç¤ºå‰5ä¸ª
                })
        
        # æŒ‰åˆ†æ•°æ’åº
        node_scores.sort(key=lambda x: x['score'], reverse=True)
        
        print("ğŸ† åŒ¹é…ç»“æœæ’åº:")
        for i, result in enumerate(node_scores[:5]):
            print(f"  {i+1}. {result['node_id']}: {result['score']:.1f}åˆ†")
            print(f"     åŒ¹é…è¯: {', '.join(result['matched_terms'])}")
            print(f"     ç´¢å¼•è¯: {', '.join(result['index_terms'])}")
            print()

def analyze_chair_on_yline_bias(data):
    """åˆ†æchair_on_ylineçš„åå·®"""
    if not data or 'input' not in data or 'topology' not in data['input']:
        return
    
    nodes = data['input']['topology']['nodes']
    chair_node = None
    
    for node in nodes:
        if node['id'] == 'chair_on_yline':
            chair_node = node
            break
    
    if not chair_node:
        print("âŒ æœªæ‰¾åˆ°chair_on_ylineèŠ‚ç‚¹")
        return
    
    print("ğŸ” åˆ†æchair_on_ylineçš„ç´¢å¼•è¯")
    print("=" * 40)
    
    index_terms = chair_node.get('retrieval', {}).get('index_terms', [])
    print(f"ç´¢å¼•è¯æ•°é‡: {len(index_terms)}")
    print("ç´¢å¼•è¯åˆ—è¡¨:")
    for i, term in enumerate(index_terms):
        print(f"  {i+1}. {term}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡äºå®½æ³›çš„ç´¢å¼•è¯
    broad_terms = []
    for term in index_terms:
        if len(term.split()) <= 2:  # çŸ­è¯å¯èƒ½è¿‡äºå®½æ³›
            broad_terms.append(term)
    
    if broad_terms:
        print(f"\nâš ï¸ å¯èƒ½è¿‡äºå®½æ³›çš„ç´¢å¼•è¯: {', '.join(broad_terms)}")
        print("è¿™äº›è¯å¯èƒ½å¯¼è‡´è¯¯åŒ¹é…")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•è¯­ä¹‰åŒ¹é…é—®é¢˜")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    data = load_structure_data()
    if not data:
        return
    
    # åˆ†æèŠ‚ç‚¹ç´¢å¼•è¯
    analyze_node_index_terms(data)
    
    # åˆ†æchair_on_ylineåå·®
    analyze_chair_on_yline_bias(data)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š åˆ†æå®Œæˆ")
    print("\nğŸ’¡ å»ºè®®:")
    print("1. æ£€æŸ¥chair_on_ylineçš„ç´¢å¼•è¯æ˜¯å¦è¿‡äºå®½æ³›")
    print("2. è°ƒæ•´ç»“æ„é€šé“å’Œç»†èŠ‚é€šé“çš„æƒé‡")
    print("3. å¢å¼ºè¯­ä¹‰å»é‡é€»è¾‘")
    print("4. æ·»åŠ å†…å®¹ç›¸å…³æ€§æ£€æŸ¥")

if __name__ == "__main__":
    main()
