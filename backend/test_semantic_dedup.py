#!/usr/bin/env python3
"""
æµ‹è¯•è¯­ä¹‰å»é‡ä¿®å¤çš„è„šæœ¬
"""

import os
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

def test_semantic_deduplication():
    """æµ‹è¯•è¯­ä¹‰å»é‡åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•è¯­ä¹‰å»é‡åŠŸèƒ½...")
    
    # æ¨¡æ‹ŸEnhancedDualChannelRetrieverç±»
    class MockRetriever:
        def _semantic_deduplication(self, candidates, caption_lower):
            """è¯­ä¹‰å»é‡ï¼šåˆå¹¶è¯­ä¹‰ç›¸ä¼¼çš„èŠ‚ç‚¹ï¼Œé¿å…è¿”å›é‡å¤çš„TV screenç­‰"""
            if not candidates:
                return candidates
            
            # å®šä¹‰è¯­ä¹‰ç›¸ä¼¼ç»„
            semantic_groups = {
                "tv_screen_group": [
                    "tv screen", "large tv screen", "large tv screen near entry",
                    "tv", "television", "display", "screen", "monitor"
                ],
                "window_group": [
                    "glass window", "window wall", "windows", "glass", "window"
                ],
                "sofa_group": [
                    "orange sofa", "sofa", "couch", "seating", "chair"
                ],
                "space_group": [
                    "open space", "large open space", "open area", "atrium", "space"
                ],
                "boxes_group": [
                    "boxes", "box", "cardboard", "stacked", "floor", "on floor"
                ],
                "table_group": [
                    "table", "desk", "workbench", "surface", "counter"
                ],
                "storage_group": [
                    "storage", "shelf", "cabinet", "drawer", "container"
                ]
            }
            
            # æŒ‰è¯­ä¹‰ç»„åˆ†ç»„å€™é€‰
            grouped_candidates = {}
            for candidate in candidates:
                candidate_id = candidate["id"].lower()
                candidate_text = candidate.get("text", "").lower()
                candidate_name = candidate.get("name", "").lower()
                
                # æ£€æŸ¥å±äºå“ªä¸ªè¯­ä¹‰ç»„
                assigned_group = None
                best_match_score = 0
                
                for group_name, keywords in semantic_groups.items():
                    match_score = 0
                    for keyword in keywords:
                        # æ£€æŸ¥å€™é€‰çš„å„ä¸ªå­—æ®µ
                        if keyword in candidate_id:
                            match_score += 2  # IDåŒ¹é…ç»™äºˆæœ€é«˜æƒé‡
                        if keyword in candidate_text:
                            match_score += 1.5  # æ–‡æœ¬åŒ¹é…ç»™äºˆé«˜æƒé‡
                        if keyword in candidate_name:
                            match_score += 1.0  # åç§°åŒ¹é…ç»™äºˆä¸­ç­‰æƒé‡
                    
                    # é€‰æ‹©åŒ¹é…åº¦æœ€é«˜çš„ç»„
                    if match_score > best_match_score:
                        best_match_score = match_score
                        assigned_group = group_name
                
                # å¦‚æœåŒ¹é…åº¦å¤ªä½ï¼Œåˆ™ä¸åˆ†ç»„
                if best_match_score < 1.0:
                    assigned_group = None
                
                if assigned_group:
                    if assigned_group not in grouped_candidates:
                        grouped_candidates[assigned_group] = []
                    grouped_candidates[assigned_group].append(candidate)
                else:
                    # ä¸å±äºä»»ä½•ç»„çš„å€™é€‰ï¼Œå•ç‹¬å¤„ç†
                    if "other" not in grouped_candidates:
                        grouped_candidates["other"] = []
                    grouped_candidates["other"].append(candidate)
            
            # å¯¹æ¯ä¸ªè¯­ä¹‰ç»„ï¼Œé€‰æ‹©æœ€é«˜åˆ†çš„å€™é€‰
            deduplicated = []
            for group_name, group_candidates in grouped_candidates.items():
                if group_name == "other":
                    # å…¶ä»–å€™é€‰ç›´æ¥æ·»åŠ 
                    deduplicated.extend(group_candidates)
                else:
                    # è¯­ä¹‰ç»„é€‰æ‹©æœ€é«˜åˆ†çš„
                    if len(group_candidates) > 1:
                        print(f"ğŸ” Semantic deduplication: {group_name} has {len(group_candidates)} candidates")
                        for i, cand in enumerate(group_candidates):
                            print(f"   {i+1}. {cand['id']} (score: {cand['score']:.3f})")
                    
                    # é€‰æ‹©æœ€é«˜åˆ†çš„å€™é€‰
                    best_candidate = max(group_candidates, key=lambda x: x["score"])
                    best_candidate["semantic_group"] = group_name
                    best_candidate["merged_candidates"] = len(group_candidates)
                    deduplicated.append(best_candidate)
            
            print(f"ğŸ” Semantic deduplication: {len(candidates)} â†’ {len(deduplicated)} candidates")
            return deduplicated
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_candidates = [
        {"id": "boxes on floor", "text": "boxes on floor", "name": "boxes on floor", "score": 0.602},
        {"id": "cardboard boxes", "text": "cardboard boxes", "name": "cardboard boxes", "score": 0.550},
        {"id": "open atrium ahead beyond stacked boxes", "text": "open atrium ahead beyond stacked boxes", "name": "open atrium ahead beyond stacked boxes", "score": 0.417},
        {"id": "tv screen", "text": "large tv screen", "name": "tv zone", "score": 0.800},
        {"id": "display monitor", "text": "computer monitor", "name": "monitor area", "score": 0.750},
        {"id": "orange sofa", "text": "orange sofa corner", "name": "sofa area", "score": 0.600},
        {"id": "chair seating", "text": "chair on yellow line", "name": "chair zone", "score": 0.550}
    ]
    
    print("ğŸ§ª æµ‹è¯•å€™é€‰åˆ—è¡¨:")
    for i, candidate in enumerate(test_candidates):
        print(f"   {i+1}. {candidate['id']} (score: {candidate['score']:.3f})")
    
    # æµ‹è¯•è¯­ä¹‰å»é‡
    retriever = MockRetriever()
    caption = "there are boxes on the floor with some cardboard boxes"
    deduplicated = retriever._semantic_deduplication(test_candidates, caption.lower())
    
    print(f"\nğŸ” å»é‡ç»“æœ:")
    for i, candidate in enumerate(deduplicated):
        semantic_group = candidate.get("semantic_group", "other")
        merged_count = candidate.get("merged_candidates", 1)
        print(f"   {i+1}. {candidate['id']} (score: {candidate['score']:.3f}) - {semantic_group} (merged {merged_count})")

if __name__ == "__main__":
    print("ğŸ§ª è¯­ä¹‰å»é‡ä¿®å¤æµ‹è¯•")
    print("=" * 50)
    
    test_semantic_deduplication()
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
